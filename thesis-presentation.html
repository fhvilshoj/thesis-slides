<!doctype html>
<html>
<head>
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=no">

    <title>Thesis Presentation</title>

    <link rel="stylesheet" href="dist/reset.css">
    <link rel="stylesheet" href="dist/reveal.css">
    <link rel="stylesheet" href="dist/theme/white.css">
    <link rel="stylesheet" href="dist/custom.css">

    <!-- Theme used for syntax highlighted code -->
    <link rel="stylesheet" href="plugin/highlight/monokai.css">
</head>
<body>
<div class="reveal">
    <header class="f-header" style="">
        <div class="f-progress-bar">
            <div class="f-progress-indicator f-progress-motivation"></div>
            <div class="f-progress-indicator f-progress-algo"></div>
            <div class="f-progress-indicator f-progress-ecinn"></div>
            <div class="f-progress-indicator f-progress-eval"></div>
            <div class="f-progress-indicator f-progress-conclusion"></div>
        </div>
    </header>
    <div class="slides">
        <section data-state="no-bar" data-auto-animate>
            <h3 data-id="title" class="r-fit-text">Fast and Explainable Deep Neural Networks</h3>

            <ul class="text-blue">
                <li><i style="color:darkred;">5</i> sections</li> <!-- TODO -->
                <li><i style="color: darkred">Y</i> images</li> <!-- TODO -->
                <li>Slide numbers and questions.</li>
            </ul>
            <div class="section-footer" style="margin-top: 30px">
                <small class="text-gray">
                    By <a class="text-blue" href="https://fhvilshoj.github.com" target="_blank">Frederik Hvilsh√∏j</a>,
                    Supervised by
                    <a class="text-blue"
                       href="https://pure.au.dk/portal/en/persons/ira-assent(012c1c28-bfa9-4107-bd8f-97dae008b06d).html"
                       target="_blank">Ira Assent</a>
                    and
                    <a class="text-blue"
                       href="https://pure.au.dk/portal/da/persons/alexandros-iosifidis(7c71a32d-a849-4a2e-b5d9-06970c846ed1).html"
                       target="_blank">Alexandros Iosifidis</a>.
                </small>
            </div>
        </section>

        <section data-state="no-bar" data-background-color="var(--au-blue-dark)">
            <h2>Introduction</h2>
        </section>
        <section data-state="motivation-header">
            <section data-auto-animate>
                <video data-id="1" src="assets/classification.mp4" autoplay="autoplay"
                       style="max-width: 100%; max-height: 80%;"></video>
                <p data-id="2"><small style="font-size: small;">Source: <a
                        href="https://www.youtube.com/watch?v=aircAruvnKk">3Blue1Brown</a></small></p>
            </section>
            <section data-auto-animate>
                <img data-id="1" src="assets/car.gif" style="max-width: 100%; max-height: 80%">
                <p data-id="2"><small style="font-size: small;">Source: <a
                        href="https://tenor.com/view/tesla-autonaume-autoconduite-driving-car-gif-15478918">Tenor.com</a></small>
                </p>
            </section>
            <section data-auto-animate>
                <img data-id="1" src="assets/alphafold.gif" style="max-width: 80%; max-height: 60%">
                <p data-id="2"><small style="font-size: small">Source: <a
                        href="https://fortune.com/2020/11/30/deepmind-solved-protein-folding-alphafold/">Fortune.com</a></small>
                </p>
            </section>
            <section data-auto-animate>
                <p>Scaling is expensive</p>
                <p><small class="text-blue-dark">ImageNet Image classification</small></p>
                <!--                <img data-id="1" src="assets/param-chart.svg" style="max-width: 80%; max-height: 60%">-->
                <img data-id="1" src="assets/param-chart.svg" class="r-stretch">
                <p data-id="2"><small style="font-size: small">Source: <a
                        href="https://paperswithcode.com/sota/image-classification-on-imagenet?metric=Top%205%20Accuracy&dimension=Number%20of%20params">Papers
                    with code.</a></small></p>
            </section>
            <section data-auto-animate>
                <p>Scaling is expensive</p>
                <p><small class="text-blue-dark">Generative language models</small></p>
                <!--                <img data-id="1" src="https://developer-blogs.nvidia.com/wp-content/uploads/2021/10/Model-Size-Chart.png" style="max-width: 80%; max-height: 60%">-->
                <img data-id="1"
                     src="https://developer-blogs.nvidia.com/wp-content/uploads/2021/10/Model-Size-Chart.png"
                     class="r-stretch">
                <p data-id="2"><small style="font-size: small">Source: <a
                        href="https://developer.nvidia.com/blog/using-deepspeed-and-megatron-to-train-megatron-turing-nlg-530b-the-worlds-largest-and-most-powerful-generative-language-model/">NVIDIA
                    Developer blog</a></small></p>
            </section>
        </section>

        <section data-state="motivation-header">
            <section data-auto-animate>
                <div data-id="hypothesis">
                    We hypothesize that crossing generative models with explainability can
                    produce state-of-the-art methods for explaining neural networks.
                </div>
            </section>
            <section data-auto-animate>
                <div data-id="hypothesis" style="font-size: smaller; color: var(--au-gray); margin-bottom: 50px;">
                    We hypothesize that crossing generative models with explainability can
                    produce state-of-the-art methods for explaining neural networks.
                </div>
                <div class="f-container">
                    <div class="f-col" data-id="rq1">
                        <div class="f-definition f-col">
                            <div class="f-header" style="background-color: var(--au-purple-dark)">RQ1</div>
                            <div class="f-content">
                                How can the <i class="f-emph">efficiency</i> of machine learning <i class="f-emph">algorithms</i>
                                be improved?
                            </div>
                        </div>
                    </div>
                    <div class="f-col" style="visibility: hidden;" data-id="rq2">
                        <div class="f-definition f-col">
                            <div class="f-header" style="background-color: var(--au-turkis-dark)">RQ2</div>
                            <div class="f-content">
                                How can <i class="f-emph">generative models</i> be utilized for <i class="f-emph">explaining</i>
                                neural networks?
                            </div>
                        </div>
                    </div>
                    <div class="f-col" style="visibility: hidden;" data-id="rq3">
                        <div class="f-definition">
                            <div class="f-header" style="background-color: var(--au-green-dark)">RQ3</div>
                            <div class="f-content">
                                How are methods for explaining neural networks best <i class="f-emph">evaluated</i>?
                            </div>
                        </div>
                    </div>
                </div>
            </section>
            <section data-auto-animate>
                <div data-id="hypothesis" style="font-size: smaller; color: var(--au-gray); margin-bottom: 50px;">
                    We hypothesize that crossing generative models with explainability can
                    produce state-of-the-art methods for explaining neural networks.
                </div>
                <div class="f-container">
                    <div class="f-col" data-id="rq1">
                        <div class="f-definition f-col">
                            <div class="f-header" style="background-color: var(--au-purple-dark)">RQ1</div>
                            <div class="f-content">
                                How can the <i class="f-emph">efficiency</i> of machine learning <i class="f-emph">algorithms</i>
                                be improved?
                            </div>
                        </div>
                    </div>
                    <div class="f-col" data-id="rq2">
                        <div class="f-definition f-col">
                            <div class="f-header" style="background-color: var(--au-turkis-dark)">RQ2</div>
                            <div class="f-content">
                                How can <i class="f-emph">generative models</i> be utilized for <i class="f-emph">explaining</i>
                                neural networks?
                            </div>
                        </div>
                    </div>
                    <div class="f-col" style="visibility: hidden" data-id="rq3">
                        <div class="f-definition">
                            <div class="f-header" style="background-color: var(--au-green-dark)">RQ3</div>
                            <div class="f-content">
                                How are methods for explaining neural networks best <i class="f-emph">evaluated</i>?
                            </div>
                        </div>
                    </div>
                </div>
            </section>
            <section data-auto-animate>
                <div data-id="hypothesis" style="font-size: smaller; color: var(--au-gray); margin-bottom: 50px;">
                    We hypothesize that crossing generative models with explainability can
                    produce state-of-the-art methods for explaining neural networks.
                </div>
                <div class="f-container">
                    <div class="f-col" data-id="rq1">
                        <div class="f-definition f-col">
                            <div class="f-header" style="background-color: var(--au-purple-dark)">RQ1</div>
                            <div class="f-content">
                                How can the <i class="f-emph">efficiency</i> of machine learning <i class="f-emph">algorithms</i>
                                be improved?
                            </div>
                        </div>
                    </div>
                    <div class="f-col" data-id="rq2">
                        <div class="f-definition f-col">
                            <div class="f-header" style="background-color: var(--au-turkis-dark)">RQ2</div>
                            <div class="f-content">
                                How can <i class="f-emph">generative models</i> be utilized for <i class="f-emph">explaining</i>
                                neural networks?
                            </div>
                        </div>
                    </div>
                    <div class="f-col" data-id="rq3">
                        <div class="f-definition">
                            <div class="f-header" style="background-color: var(--au-green-dark)">RQ3</div>
                            <div class="f-content">
                                How are methods for explaining neural networks best <i class="f-emph">evaluated</i>?
                            </div>
                        </div>
                    </div>
                </div>
            </section>
        </section>
        <section data-state="motivation-header">
            <ul>
                <li>
                    <p class="r-stretch"><b class="text-purple">Paper 1</b> What if Neural Networks Had SVDs?</p>
                    <small>Alexander Mathiasen, Frederik Hvilsh√∏j, Jakob R√∏dsgaard J√∏rgensen, Anshul Nasery, and Davide
                        Mottin. In NeurIPS, 2020.
                    </small>
                </li>
                <li><b class="text-purple">Paper 2</b> Backpropagating through Fr√©chet Inception Distance<br>
                    <small>Alexander Mathiasen and Frederik Hvilsh√∏j. CoRR,
                        <a href="https://arxiv.org/abs/2009.14075" target="_blank">abs/2009.14075</a>, 2020.
                    </small>
                </li>
                <li> <b class="text-turkis">Paper 3</b> ECINN: Efficient Counterfactuals from Invertible Neural Networks.
                    <small>Frederik Hvilsh√∏j, Alexandros Iosifidis, and Ira Assent.  In BMVC, 2021.</small>
                </li>
                <li><b class="text-green">Paper 4</b> On Quantitative Evaluations of Counterfactuals.
                    <small>Frederik Hvilsh√∏j, Alexandros Iosifidis, and Ira Assent.  CoRR, <a href="https://arxiv.org/abs/2111.00177">abs/2111.00177</a>, 2021. </small>
                </li>
            </ul>
        </section>

        <section data-state="no-bar" data-background-color="var(--au-purple-dark)">
            <h2>Efficient Neural Network Training</h2>
            <p>
                RQ1: How can the <i class="f-emph">efficiency</i> of machine learning <i class="f-emph">algorithms</i>
                be improved?
            </p>
        </section>
        <section data-state="algo-header">
            <section data-auto-animate>
                <h3 data-id="header">What if Neural Networks had SVDs?</h3>
            </section>
            <section data-auto-animate data-state="algo-header">
                <h3 data-id=header" style="font-size: smaller; color: var(--au-gray); margin-bottom: 50px;">What if Neural Networks had SVDs?</h3>
                <span data-id="1">
                \[
                    W\in \mathbb{R}^{d \times d}
                \]
                </span>
            </section>
            <section data-auto-animate data-state="algo-header">
                <h3 data-id=header" style="font-size: smaller; color: var(--au-gray); margin-bottom: 50px;">What if Neural Networks had SVDs?</h3>
                <span data-id="1">
                \[
                W\in \mathbb{R}^{d \times d}
                \]
                </span>
                <span data-id="2">
                   $ W = U \Sigma V^\intercal,$
                    <span style="margin-left: 20px; font-size: smaller; color: var(--au-gray)">
                        $U,V,\Sigma \in \mathbb{R}^{d\times d}$
                    </span>
                </span>
            </section>
            <section data-auto-animate data-state="algo-header">
                <h3 data-id=header" style="font-size: smaller; color: var(--au-gray); margin-bottom: 50px;">What if Neural Networks had SVDs?</h3>
                <span data-id="1">
                \[
                W\in \mathbb{R}^{d \times d}
                \]
                </span>
                <span data-id="2">
                   $ W = U \Sigma V^\intercal,$
                    <span style="margin-left: 20px; font-size: smaller; color: var(--au-gray)">
                        $U,V,\Sigma \in \mathbb{R}^{d\times d}$
                    </span>
                </span>
                <span data-id="3">
                    \[
                        U^{-1} = U^\intercal, V^{-1} = V^\intercal \quad\Rightarrow\quad W^{-1} = V\Sigma U^\intercal
                    \]
                </span>
            </section>
            <section data-auto-animate>
                <span data-id="2" class="text-gray">
                   $ W = U \Sigma V^\intercal,$
                    <span style="margin-left: 20px; font-size: smaller; color: var(--au-gray)">
                        $U,V,\Sigma \in \mathbb{R}^{d\times d}$
                    </span>
                </span>

                <span data-id="3" class="text-gray">
                    \[
                        U^{-1} = U^\intercal, V^{-1} = V^\intercal \quad\Rightarrow\quad W^{-1} = V\Sigma^{-1} U^\intercal
                    \]
                </span>
                <div data-id="4">
                    <p>The neural network setting</p>
                    \[
                    y = \sigma( \color{blue}Wx ) \quad \color{blue}W^{\color{blue}-\color{blue}1}\sigma^{-1}(y) = x
                    \]
                </div>

            </section>
            <section data-auto-animate>
                <span data-id="2" class="text-gray">
                   $ W = U \Sigma V^\intercal,$
                    <span style="margin-left: 20px; font-size: smaller; color: var(--au-gray)">
                        $U,V,\Sigma \in \mathbb{R}^{d\times d}$
                    </span>
                </span>

                <span data-id="3" class="text-gray">
                    \[
                        U^{-1} = U^\intercal, V^{-1} = V^\intercal \quad\Rightarrow\quad W^{-1} = V\Sigma^{-1} U^\intercal
                    \]
                </span>
                <div data-id="4">
                    <p>The neural network setting</p>
                    \[
                    y = \sigma( \color{blue}U\color{blue}\Sigma \color{blue}V^{\color{blue}\intercal} x ) \quad \color{blue}V\color{blue}\Sigma^{\color{blue}-\color{blue}1}\color{blue}U^{\color{blue}\intercal}\sigma^{-1}(y) = x
                    \]
                </div>
            </section>
            <section data-auto-animate>
                <span data-id="2" class="text-gray">
                   $ W = U \Sigma V^\intercal,$
                    <span style="margin-left: 20px; font-size: smaller; color: var(--au-gray)">
                        $U,V,\Sigma \in \mathbb{R}^{d\times d}$
                    </span>
                </span>

                <span data-id="3" class="text-gray">
                    \[
                        U^{-1} = U^\intercal, V^{-1} = V^\intercal \quad\Rightarrow\quad W^{-1} = V\Sigma^{-1} U^\intercal
                    \]
                </span>
                <div data-id="4">
                    <p>The neural network setting</p>
                    \[
                    y = \sigma( \color{blue}U\color{blue}\Sigma \color{blue}V^{\color{blue}\intercal} x ) \quad \color{blue}V\color{blue}\Sigma^{\color{blue}-\color{blue}1}\color{blue}U^{\color{blue}\intercal}\sigma^{-1}(y) = x
                    \]
                </div>
                <p data-id="5">$O(d^3)$ to $O(d)$</p>
            </section>
            <section data-auto-animate>
                <p><span class="text-purple">Problem:</span> Gradient descent on $U$ and $V$ does <u class="text-blue">not</u> maintain orthogonality.</p>
            </section>
            <section data-auto-animate>
                <p><span class="text-purple">Problem:</span> Gradient descent on $U$ and $V$ does <u class="text-blue">not</u> maintain orthogonality.</p>
                <p><span class="text-purple">Solution:</span> Different parametrization of $U$ and $V$ [93]</p>
            </section>
            <section data-auto-animate>
                <div data-id="1">
                    \[
                        U=\prod_{i=1}^{d} H_{i} \quad H_{i}=I-2 \frac{v_{i} v_{i}^{T}}{\left\|v_{i}\right\|_{2}^{2}} \quad v_{i} \in \mathbb{R}^{d}
                    \]
                </div>
            </section>
            <section data-auto-animate>
                <div data-id="1">
                    \[
                    U=\prod_{i=1}^{d} H_{i} \quad H_{i}=I-2 \frac{v_{i} v_{i}^{T}}{\left\|v_{i}\right\|_{2}^{2}} \quad v_{i} \in \mathbb{R}^{d}
                    \]
                </div>
                <div data-id="2">
                    \[
                        UX = H_1\cdots (H_{d-1}(H_d\cdot X) \dots )
                    \]
                </div>
            </section>
            <section data-auto-animate>
                <div data-id="1">
                    \[
                    U=\prod_{i=1}^{d} H_{i} \quad H_{i}=I-2 \frac{v_{i} v_{i}^{T}}{\left\|v_{i}\right\|_{2}^{2}} \quad v_{i} \in \mathbb{R}^{d}
                    \]
                </div>
                <div data-id="2">
                    \[
                    UX = H_1\cdots (H_{d-1}(H_d\cdot X) \dots )
                    \]
                </div>
                <p data-id="3">For $X \in \mathbb{R}^{d\times m}$, complexity is $O(d^2m)$ üëç </p>
                <p data-id="4">Very sequential üëé</p>
            </section>
            <section>
                <img src="assets/fasth_compare.png" class="r-stretch"/>
            </section>
            <section>
                <h4 style="display: inline" class="text-purple">Problem: </h4>
                <p style="display: inline;">Given $X$ and $v_1, ..., v_d$, can we compute the product
                    $$\left[\prod_{i=1}^{d} I-2 \frac{v_{i} v_{i}^{\top}}{\left\|v_{i}\right\|_{2}^{2}}\right] X=\left[\prod_{i=1}^{d} H_{i}\right] X$$
                     in $O(d^2n)$ time with less than $O(d)$ sequential work?
                </p><br/>
            </section>
            <section data-auto-animate>
                <h4 style="display: inline" class="text-purple">Solution: </h4>
                <p style="display: inline;">Compute sub-products in parallel.</p>
            </section>
            <section data-auto-animate>
                <h4 style="display: inline" class="text-purple">Solution: </h4>
                <p style="display: inline;">Compute sub-products in parallel.</p>
                <div data-auto-animate-id="1" class="lemma smaller-font">
                    <p>
                        <b>Lemma 1: [8]</b>
                        For any $t$ Householder matrices $H_1,...,H_t$, there exists $W, Y\in \mathbb{R}^{d\times t}$ st.
                        $I‚àí WY^\intercal = H_1 \cdots H_t$. <br/>
                        Computing $W$ and $Y$ takes $O(dt^2)$ time and $t$ sequential matrix-matrix multiplications.
                    </p>
                </div>
            </section>
            <section data-auto-animate>
                <h4 style="display: inline" class="text-purple">Solution: </h4>
                <p style="display: inline;">Compute sub-products in parallel.</p>
                <div data-auto-animate-id="1"class="lemma smaller-font">
                    <p>
                        <b>Lemma 1: [8]</b>
                        For any $t$ Householder matrices $H_1,...,H_t$, there exists $W, Y\in \mathbb{R}^{d\times t}$ st.
                        $I‚àí WY^\intercal = H_1 \cdots H_t$. <br/>
                        Computing $W$ and $Y$ takes $O(dt^2)$ time and $t$ sequential matrix-matrix multiplications.
                    </p>
                </div>
                <div class="smaller-font">
                    <p><span class="text-purple">Step 1:</span> Compute sub-products in parallel.</p>
                    <p>$
                        \begin{array}{cccc}
                        H_{1} \ldots H_{t} & H_{t+1} \ldots H_{2 t} & \ldots & H_{d-t+1} \ldots H_{d} \\
                        \| & \| & \ldots & \| \\
                        G_{1}=I-W_{1} Y_{1}^{\top} & G_{2}=I-W_{2} Y_{2}^{\top} & \ldots & G_{d / t}=I-W_{d / t} Y_{d / t}^{\top}
                        \end{array}
                        $</p>
                </div>
            </section>
            <section data-auto-animate>
                <h4 style="display: inline" class="text-purple">Solution: </h4>
                <p style="display: inline;">Compute sub-products in parallel.</p>
                <div data-auto-animate-id="1" class="lemma smaller-font">
                    <p>
                        <b>Lemma 1: [8]</b>
                        For any $t$ Householder matrices $H_1,...,H_t$, there exists $W, Y\in \mathbb{R}^{d\times t}$ st.
                        $I‚àí WY^\intercal = H_1 \cdots H_t$. <br/>
                        Computing $W$ and $Y$ takes $O(dt^2)$ time and $t$ sequential matrix-matrix multiplications.
                    </p>
                </div>
                <div class="smaller-font">
                    <p><span class="text-purple">Step 1:</span> Compute sub-products in parallel.</p>
                    <p>$
                    \begin{array}{cccc}
                    H_{1} \ldots H_{t} & H_{t+1} \ldots H_{2 t} & \ldots & H_{d-t+1} \ldots H_{d} \\
                    \| & \| & \ldots & \| \\
                    G_{1}=I-W_{1} Y_{1}^{\top} & G_{2}=I-W_{2} Y_{2}^{\top} & \ldots & G_{d / t}=I-W_{d / t} Y_{d / t}^{\top}
                    \end{array}
                        $
                    </p>
                </div>
                <div class="smaller-font">
                    <p><span class="text-purple">Step 2:</span> Compute full product sequentially.</p>
                    \[
                        UX = G_1(G_2(...(G_{d/t}X)...)
                    \]
                </div>
            </section>
            <section data-auto-animate>
                <h4>Time complexity:</h4>
                <div data-auto-animate-id="1" class="smaller-font">
                    <p>Asymptotic running time:</p>
                    <table>
                        <tr>
                            <td><i class="text-purple">Step 1:</i></td>
                            <td>Computing $d/t$ products: </td>
                            <td>$O(d/t \cdot dt^2) = O(d^2t)$</td>
                        </tr>
                        <tr>
                            <td><i class="text-purple">Step 2:</i></td>
                            <td>Computing the full product: </td>
                            <td>$O(d/t \cdot dtm) = O(d^2m)$</td>
                        </tr>
                        <tr>
                            <td><i class="text-purple">Total:</i></td>
                            <td>If $t = m$</td>
                            <td>$O(d^2m)$ ‚úÖ</td>
                        </tr>
                    </table>
                </div>
            </section>
            <section data-auto-animate>
                <h4>Time complexity:</h4>
                <div data-auto-animate-id="1" class="smaller-font">
                    <p>Asymptotic running time:</p>
                    <table>
                        <tr>
                            <td><i class="text-purple">Step 1:</i></td>
                            <td>Computing $d/t$ products: </td>
                            <td>$O(d/t \cdot dt^2) = O(d^2t)$</td>
                        </tr>
                        <tr>
                            <td><i class="text-purple">Step 2:</i></td>
                            <td>Computing the full product: </td>
                            <td>$O(d/t \cdot dtm) = O(d^2m)$</td>
                        </tr>
                        <tr>
                            <td><i class="text-purple">Total:</i></td>
                            <td>If $t = m$</td>
                            <td>$O(d^2m)$ ‚úÖ</td>
                        </tr>
                    </table>
                </div>

                <div data-auto-animate-id="2" class="smaller-font">
                    <p>Sequential work.</p>
                    <table>
                        <tr>
                            <td><i class="text-purple">Step 1:</i></td>
                            <td>Computing $d/t$ products: </td>
                            <td>$O(t)$</td>
                        </tr>
                        <tr>
                            <td><i class="text-purple">Step 2:</i></td>
                            <td>Computing the full product: </td>
                            <td>$O(d/t)$</td>
                        </tr>
                        <tr>
                            <td><i class="text-purple">Total: </i></td>
                            <td></td>
                            <td>$O(t + d/t)$ ‚úÖ</td>
                        </tr>
                    </table>

                </div>
            </section>
            <section>
                <img src="assets/fasth_compare2.png" class="r-stretch"/>
            </section>
            <section>
                <img src="assets/fasth_training.png" class="r-stretch"/>
            </section>
        </section>
        <!--
             What if Neural Networks had SVDs?
             Backpropagating through Fr√©chet Inception Distance
             Discussion
        -->

        <section data-state="no-bar" data-background-color="var(--au-turkis-dark)">
            <h2>Counterfactual Examples</h2>
            <p>
                RQ2: How can <i class="f-emph">generative models</i> be utilized for <i class="f-emph">explaining</i>
                neural networks?
            </p>
        </section>
        <section data-state="cf-header">
            <p>header1 example</p>
        </section>
        <!--
             Generating Visual Counterfactual Examples
             Efficient Counterfactuals from INNs
             Discussion
        -->


        <section data-state="no-bar" data-background-color="var(--au-green-dark)">
            <h2>Evaluating Counterfactual Examples</h2>
            <p>
                RQ3: How are methods for explaining neural networks best <i class="f-emph">evaluated</i>?
            </p>
        </section>
        <section data-state="eval-header">

        </section>

        <!--
             Existing Quantitative Metrics
             On Quantitative Evaluations of Counterfactuals
             Discussion
        -->

        <section data-state="no-bar" data-background-color="var(--au-blue-dark)">
            <h2>Conclusion</h2>
        </section>

        <section data-state="conclusion-header">
            <h2>Hello there!</h2>
        </section>
        <!--
             Discussion
             Conclusion
             Future Work
        -->
        <section class="references">
            <p>References:</p>
            <ul>
                <li>[8] Christian Bischof and Charles Van Loan. The WY Representation for Products
                    of Householder Matrices. SIAM Journal on Scientific and Statistical Computing,
                    1987.</li>
                <li>[93] Jiong Zhang, Qi Lei, and Inderjit S. Dhillon. Stabilizing gradients for deep
                    neural networks via efficient SVD parameterization. In ICML, 2018. 8, 10, 11, 12
                </li>
            </ul>

        </section>
    </div>
    <footer class="f-footer" style="">
        <div class="f-progress-bar">
            <div class="f-progress-indicator f-progress-motivation"></div>
            <div class="f-progress-indicator f-progress-algo"></div>
            <div class="f-progress-indicator f-progress-ecinn"></div>
            <div class="f-progress-indicator f-progress-eval"></div>
            <div class="f-progress-indicator f-progress-conclusion"></div>
        </div>
    </footer>
</div>

<script src="dist/reveal.js"></script>
<script src="plugin/notes/notes.js"></script>
<script src="plugin/math/math.js"></script>
<script src="plugin/markdown/markdown.js"></script>
<script src="plugin/highlight/highlight.js"></script>
<script type="text/javascript">
    const key_presses = [];
    const append = function(arr, item) {
        const idx = arr.length;
        arr.splice( idx, 0, item );
    }
    const pop = function(arr) {
        const l = arr.length;
        if (l === 0){
            return false;
        }
        return arr.splice(l-1,l)[0];
    };
    const go_to_slide = function(evt) {
        if (evt.keyCode === 13) { // enter
            if (key_presses.indexOf('enter') !== -1){
                let val = pop(key_presses);
                let size = 1;
                let v = 0;
                while(val !== 'enter') {
                    v = v + size *  val;
                    size = size * 10;
                    val = pop(key_presses)
                }

                let h = 0;
                size = 1;
                val = pop(key_presses);
                while(val !== false) {
                    h = h + size * val;
                    size = size * 10;
                    val = pop(key_presses);
                }
                Reveal.slide(h-1, v-1);
            } else {
                append(key_presses, 'enter');
            }
        } else {
            append(key_presses, parseInt(evt.key, 10));
        }
    };
</script>
<script>
    Reveal.initialize({
        hash: true,
        showNotes: true,
        slideNumber: true,

        history: true,
        transition: 'linear',

        keyboard: {
            13: go_to_slide,
            48: go_to_slide,
            49: go_to_slide,
            50: go_to_slide,
            51: go_to_slide,
            52: go_to_slide,
            53: go_to_slide,
            54: go_to_slide,
            55: go_to_slide,
            56: go_to_slide,
            57: go_to_slide,
        },

        mathjax2: {
            config: 'TeX-AMS_HTML-full',
            loader: {load: ['[tex]/color']},
            TeX: {
                packages: {'[+]': ['color']},
                Macros: {
                    R: '\\mathbb{R}',
                    set: ['\\left\\{#1 \\; ; \\; #2\\right\\}', 2]
                }
            }
        },

        // Learn about plugins: https://revealjs.com/plugins/
        plugins: [RevealMarkdown, RevealHighlight, RevealNotes, RevealMath.MathJax2]
    });
</script>
</body>
</html>
